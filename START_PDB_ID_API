How to get PDB ID's so you can put them in CSV list for batch download

Use this API
https://www.rcsb.org/docs/programmatic-access/web-apis-overview#search-api
______________________________________________________________________________

pip3 install requests

cd into a folder you would store general documents
nano
COPY PASTE THE FOLLOWING AND ADD YOUR OWN STUFF TO IT
ctrl+o + ENTER
pdb_request1.py
ENTER
ctrl+X

_____________________________________________________________________________________
GUIDE
https://search.rcsb.org/index.html#search-api

HOW TO GENERATE SEARCH REQUEST
https://youtu.be/0fmb_LMA_i8?si=9rz4Fx3CdaM-v1pR
_____________________________________________________________________________________
##THIS IS THE SEARCH QUERY INTO PYTHON TO GET PDB FILES FOR TCR'S
##SAVE IT AS A .py FILE

import requests
import json
import urllib.parse
import pandas as pd  # Import pandas

search_request = {  # Example search request (replace with your actua>
    "query": {
        "type": "group",
        "nodes": [
            {
                "type": "terminal",
                "service": "full_text",
                "parameters": {
                    "value": "t cell receptor"
                }
            },
            {
                "type": "terminal",
                "service": "text",
                "parameters": {
                    "attribute": "rcsb_entity_source_organism.ncbi_sc>
                    "value": "Homo sapiens",
                    "operator": "exact_match"
                }
            }
        ],
        "logical_operator": "and"
    },
    "request_options": {
        "return_all_hits": True,
        "results_content_type": ["experimental"],
        "sort": [
            {
               "sort_by": "score",
                "direction": "desc"
            }
        ],
        "scoring_strategy": "combined"
    },
    "return_type": "entry"
}

# URL encode the JSON request
url_encoded_request = urllib.parse.quote(json.dumps(search_request))
url = f"https://search.rcsb.org/rcsbsearch/v2/query?json={url_encoded>

response = requests.get(url)  # Alternatively, use requests.post(url,>

if response.status_code == 200:
    results = response.json()
    
    # Depending on the structure of results, you might need to adjust>
    # For example, if results is a list of entries:
    df = pd.DataFrame(results)  # Create a DataFrame from results
    
    # Save results to a CSV file
    df.to_csv('merged_data.csv', index=False)
    
    # Optionally, print the DataFrame to verify
    print(df)
else:
    print(f"Error: {response.status_code}")
    print(response.text)


__________________________________________________________________

#After saving this is a .py file
#type into the terminal

python3 <name_of_python_file.py>
